{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\"\"\"\n",
    "CNN architecture:\n",
    "    1. Conv layer #1: 32 5x5 filters, with ReLU\n",
    "    2. Pooling layer #1: Max pooling with a 2x2 filter and stride of 2 (pooled regions do not overlap)\n",
    "    3. Conv layer #2: 64 5x5 filters, with ReLU\n",
    "    4. Pooling layer #2: Max pooling with a 2x2 filter and stride of 2\n",
    "    5. Dense layer #1: 1,024 neurons, with dropout rate of 0.4 (will be dropped)\n",
    "    6. Dense layer #2 (Logits layer): 10 neurons, one for each digit target class (0-9)\n",
    "\"\"\"\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    # Input layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1]) # -1 can be used to flattening or infering the shape\n",
    "    \n",
    "    \n",
    "    # Conv layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv1,\n",
    "        pool_size=[2,2],\n",
    "        strides=2)\n",
    "    \n",
    "    # Conv layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling layer #2\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2,\n",
    "        pool_size=[2,2],\n",
    "        strides=2)\n",
    "    \n",
    "    # Dense layer #1\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7*7*64])\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat,\n",
    "        units=1024,\n",
    "        activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense,\n",
    "        rate=0.4,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        \n",
    "    # Dense layer #2 (Logits layer)\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add 'softmax_tensor' to the graph. It is used for PREDICT and by the 'logging_hook'.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "def main(unused_argv):\n",
    "    # Load training and eval data\n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data = mnist.train.images # Returns np.array\n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    eval_data = mnist.test.images # Returns np.array\n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "    \n",
    "    # Create the Estimator\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "        model_fn=cnn_model_fn, model_dir=\"/home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/\")\n",
    "    \n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=50)\n",
    "    \n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    mnist_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=10,\n",
    "        hooks=[logging_hook])\n",
    "    \n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04e1489160>, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_model_dir': '/home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/', '_is_chief': True, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_type': 'worker', '_num_ps_replicas': 0, '_task_id': 0, '_keep_checkpoint_max': 5, '_service': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.11309332 0.08860803 0.09202696 0.10796023 0.11617018 0.09644871\n",
      "  0.09236488 0.09301493 0.10347258 0.09684021]\n",
      " [0.12845416 0.10822992 0.07501648 0.10083193 0.09547076 0.0963779\n",
      "  0.10807057 0.09290816 0.10061161 0.09402851]\n",
      " [0.10761669 0.113626   0.1063201  0.10052414 0.10404355 0.0881194\n",
      "  0.08877609 0.09422263 0.08293777 0.11381371]\n",
      " [0.11451222 0.10368458 0.09192587 0.1231367  0.10057233 0.09174719\n",
      "  0.08674492 0.10007233 0.09566328 0.0919406 ]\n",
      " [0.11017884 0.11301722 0.1147071  0.1065611  0.09831405 0.0791676\n",
      "  0.11153193 0.07678977 0.10318936 0.08654302]\n",
      " [0.09400917 0.09821341 0.09616365 0.0959902  0.10307913 0.08512974\n",
      "  0.11146303 0.0956139  0.10676899 0.11356875]\n",
      " [0.10623226 0.0815104  0.10348079 0.11674716 0.10292078 0.09166779\n",
      "  0.08935899 0.09878296 0.10291948 0.10637935]\n",
      " [0.10763346 0.09215371 0.08568463 0.11410189 0.11070818 0.09527294\n",
      "  0.08827178 0.08698495 0.11274904 0.10643941]\n",
      " [0.11461543 0.10720016 0.0885701  0.12021462 0.09591703 0.0952465\n",
      "  0.09780568 0.08450741 0.10467982 0.09124324]\n",
      " [0.12085184 0.10121762 0.09254873 0.09830742 0.10304042 0.09793524\n",
      "  0.09160301 0.0947893  0.10503334 0.0946731 ]\n",
      " [0.09503034 0.10905791 0.07541387 0.08913731 0.09959991 0.09173384\n",
      "  0.1048767  0.1140873  0.11478803 0.10627481]\n",
      " [0.10398172 0.09060492 0.09431423 0.1070542  0.11614339 0.10161088\n",
      "  0.07982899 0.09516463 0.09671832 0.11457875]\n",
      " [0.10706948 0.11421713 0.07409337 0.10376834 0.10761435 0.09374392\n",
      "  0.09398492 0.09495258 0.10689445 0.10366146]\n",
      " [0.10620654 0.10499825 0.09235712 0.09357525 0.10829587 0.09428413\n",
      "  0.09381242 0.09996708 0.1036256  0.10287775]\n",
      " [0.10792881 0.07985994 0.0998476  0.12588198 0.09568933 0.09810542\n",
      "  0.08332576 0.10306226 0.10949837 0.09680052]\n",
      " [0.09144153 0.10101081 0.08395455 0.11036689 0.11365578 0.101438\n",
      "  0.09008279 0.09627344 0.1060522  0.10572405]\n",
      " [0.12378587 0.08838798 0.0933526  0.10482521 0.11393439 0.08730097\n",
      "  0.10365459 0.08847599 0.10629443 0.08998798]\n",
      " [0.10196447 0.09392272 0.09658664 0.11838303 0.09937502 0.0998951\n",
      "  0.07645924 0.09366802 0.11497664 0.1047691 ]\n",
      " [0.10357577 0.09184702 0.10221695 0.10692276 0.10392806 0.09352738\n",
      "  0.09404865 0.09673291 0.10543061 0.10176994]\n",
      " [0.10127818 0.10688893 0.09785347 0.11453731 0.10239121 0.09438362\n",
      "  0.09451493 0.08934547 0.09922267 0.09958418]\n",
      " [0.13761742 0.11694598 0.08270931 0.12704396 0.0854069  0.08798915\n",
      "  0.09750006 0.08670476 0.1010467  0.07703574]\n",
      " [0.09948999 0.09667204 0.09444326 0.09570299 0.10371393 0.10089131\n",
      "  0.11195592 0.09060471 0.10779928 0.09872649]\n",
      " [0.11644394 0.10757288 0.08216657 0.09787392 0.11905822 0.09572085\n",
      "  0.09917018 0.0831065  0.1012904  0.09759663]\n",
      " [0.11198527 0.09394995 0.09140965 0.10028207 0.1004767  0.0969134\n",
      "  0.10235017 0.09714905 0.10128526 0.10419846]\n",
      " [0.10280762 0.09652995 0.10191628 0.10458273 0.10956886 0.09352925\n",
      "  0.09178356 0.10121616 0.09816343 0.09990208]\n",
      " [0.11225254 0.09923854 0.09367006 0.08910425 0.10287718 0.10637386\n",
      "  0.09146719 0.09383021 0.09926274 0.1119234 ]\n",
      " [0.09785666 0.09316471 0.08275475 0.11733057 0.10667306 0.10060156\n",
      "  0.09490755 0.09749142 0.1023746  0.10684507]\n",
      " [0.112638   0.09970433 0.08948521 0.10139439 0.12367292 0.09434975\n",
      "  0.08780068 0.09222054 0.10388917 0.09484494]\n",
      " [0.1163049  0.09365136 0.10114143 0.11657913 0.10615938 0.10533451\n",
      "  0.08314267 0.08887334 0.09498325 0.09383003]\n",
      " [0.10666497 0.09928051 0.0911649  0.09446256 0.10214592 0.09601497\n",
      "  0.09910949 0.10006037 0.10022078 0.11087559]\n",
      " [0.09393153 0.10755523 0.08508503 0.12096736 0.09673799 0.09899139\n",
      "  0.10876028 0.08802029 0.1038558  0.09609504]\n",
      " [0.09934151 0.08880989 0.10273434 0.10403407 0.10919847 0.10044526\n",
      "  0.09217221 0.10218988 0.09417284 0.10690157]\n",
      " [0.11109063 0.0979301  0.08499612 0.1054408  0.10455541 0.09774648\n",
      "  0.09713862 0.09719172 0.10333755 0.1005726 ]\n",
      " [0.11156984 0.08883734 0.10823532 0.1102828  0.09370196 0.09302162\n",
      "  0.09484421 0.09436493 0.09651934 0.10862269]\n",
      " [0.10225242 0.10970094 0.09743424 0.10668775 0.10825564 0.08676435\n",
      "  0.08264642 0.09532015 0.10379939 0.10713867]\n",
      " [0.1041003  0.09787936 0.09722579 0.10815479 0.10428425 0.09066098\n",
      "  0.10663137 0.09492557 0.0997834  0.09635416]\n",
      " [0.0899246  0.11006197 0.09131067 0.11149313 0.09725234 0.09852316\n",
      "  0.09377877 0.09513491 0.10719647 0.10532397]\n",
      " [0.09985942 0.09800234 0.091405   0.12655084 0.1001986  0.1061756\n",
      "  0.09096502 0.08623776 0.10380854 0.09679685]\n",
      " [0.1061722  0.10454164 0.08326228 0.10126562 0.1067443  0.09792768\n",
      "  0.10468005 0.08618142 0.10647441 0.10275033]\n",
      " [0.1123663  0.09502836 0.09679139 0.11705431 0.10314808 0.10043331\n",
      "  0.09813965 0.09707391 0.10078219 0.07918246]\n",
      " [0.09627209 0.09661487 0.08931345 0.12485215 0.1065763  0.09523097\n",
      "  0.09883247 0.10247938 0.09164727 0.09818111]\n",
      " [0.10886823 0.11781601 0.09100031 0.09625383 0.09872154 0.0897122\n",
      "  0.10125009 0.10566074 0.10699441 0.08372264]\n",
      " [0.11650013 0.09739646 0.08383891 0.09938446 0.11180861 0.09981774\n",
      "  0.09915525 0.10100581 0.10319122 0.08790141]\n",
      " [0.11803628 0.10099579 0.08083408 0.11023407 0.0970715  0.08966589\n",
      "  0.09923176 0.09311672 0.10483921 0.10597467]\n",
      " [0.10052888 0.10766874 0.09711552 0.1073154  0.08715038 0.09188203\n",
      "  0.11157699 0.09171375 0.10456166 0.10048667]\n",
      " [0.09572972 0.08947251 0.09764849 0.12458154 0.08732637 0.08865065\n",
      "  0.09990074 0.10610534 0.1143351  0.09624959]\n",
      " [0.12190748 0.10279611 0.08600657 0.10106596 0.10485053 0.09853826\n",
      "  0.09167661 0.10113221 0.09770583 0.09432033]\n",
      " [0.09687484 0.10681222 0.09437915 0.10574231 0.0996207  0.09199818\n",
      "  0.10148707 0.09399007 0.09557535 0.11352009]\n",
      " [0.10013828 0.09419095 0.09348837 0.10840788 0.10557719 0.09906753\n",
      "  0.1005727  0.09618703 0.10153481 0.10083528]\n",
      " [0.10005377 0.10365541 0.08661085 0.11151524 0.09354141 0.09262873\n",
      "  0.09849529 0.09871893 0.1164358  0.09834457]\n",
      " [0.1090297  0.09318887 0.09246423 0.10418496 0.09894402 0.11933303\n",
      "  0.08480278 0.10005365 0.10035085 0.09764796]\n",
      " [0.10566465 0.08804713 0.09774274 0.10962792 0.10036133 0.09251445\n",
      "  0.08781244 0.10017078 0.10019104 0.11786751]\n",
      " [0.10143754 0.10751823 0.09284303 0.10130955 0.11113752 0.10175529\n",
      "  0.09240536 0.09395318 0.09038856 0.10725176]\n",
      " [0.1049094  0.1121859  0.0911281  0.10677875 0.10252189 0.09100802\n",
      "  0.09462542 0.09548791 0.09945688 0.10189771]\n",
      " [0.1206181  0.11481476 0.09507984 0.11135676 0.08468874 0.09398495\n",
      "  0.09542233 0.0896067  0.09805442 0.09637336]\n",
      " [0.1027993  0.09605618 0.09772134 0.10264961 0.09436069 0.09754796\n",
      "  0.10615139 0.10241004 0.10585839 0.09444515]\n",
      " [0.10820863 0.10084271 0.0948783  0.10496921 0.1071597  0.09564837\n",
      "  0.09897655 0.09413158 0.09558799 0.09959694]\n",
      " [0.10392516 0.09299319 0.09309724 0.10757112 0.11063949 0.08759035\n",
      "  0.10267085 0.09907836 0.09330154 0.10913271]\n",
      " [0.10541648 0.09596999 0.09052411 0.1017667  0.11913712 0.10642713\n",
      "  0.09254047 0.09496696 0.09436968 0.09888141]\n",
      " [0.1092326  0.09668428 0.09093875 0.10450581 0.1041691  0.09550665\n",
      "  0.09066202 0.09721438 0.09693238 0.11415396]\n",
      " [0.10911863 0.10398918 0.08232228 0.10517515 0.10136832 0.11331598\n",
      "  0.08985732 0.10475209 0.09135052 0.09875055]\n",
      " [0.11564256 0.09928808 0.08574189 0.08677546 0.10740279 0.09386546\n",
      "  0.09610738 0.10948279 0.1095798  0.09611385]\n",
      " [0.10455046 0.09337707 0.09305371 0.10306965 0.10606109 0.08721889\n",
      "  0.08339251 0.09869364 0.11973057 0.11085241]\n",
      " [0.09834603 0.0906306  0.09305386 0.11288386 0.10254357 0.09944209\n",
      "  0.09763126 0.1085639  0.10279962 0.0941052 ]\n",
      " [0.10593767 0.08851505 0.09866717 0.08340145 0.12998185 0.09785455\n",
      "  0.08682694 0.12288043 0.09694158 0.08899339]\n",
      " [0.10748198 0.11587604 0.08255263 0.1069025  0.1047663  0.1042857\n",
      "  0.09418877 0.08813068 0.09632061 0.09949476]\n",
      " [0.10551244 0.09918257 0.0893335  0.11090746 0.0983893  0.08405057\n",
      "  0.09216703 0.1004721  0.10831486 0.1116702 ]\n",
      " [0.10241843 0.10686491 0.08883476 0.10494587 0.0975939  0.0956346\n",
      "  0.10157347 0.08720838 0.09639202 0.11853364]\n",
      " [0.09538723 0.09664927 0.09786464 0.11435165 0.1088847  0.10125867\n",
      "  0.08562999 0.0955481  0.10403808 0.10038771]\n",
      " [0.0982041  0.11430618 0.09244933 0.10710073 0.0949273  0.1088379\n",
      "  0.10106991 0.08690159 0.10709139 0.08911164]\n",
      " [0.11197379 0.08774181 0.08204    0.11294522 0.09701699 0.10318217\n",
      "  0.09360766 0.09524586 0.09975834 0.11648811]\n",
      " [0.11329618 0.09072195 0.08968361 0.10943348 0.10227226 0.1006299\n",
      "  0.10331328 0.09768915 0.08799633 0.10496379]\n",
      " [0.11189999 0.09512866 0.07212552 0.09561637 0.10951506 0.09104946\n",
      "  0.10850311 0.10330207 0.10111899 0.11174074]\n",
      " [0.09798037 0.09458292 0.09234469 0.1164206  0.09510019 0.09379532\n",
      "  0.10895123 0.10647089 0.10088619 0.09346765]\n",
      " [0.10577963 0.10692552 0.09112794 0.09884    0.11209093 0.10181088\n",
      "  0.082909   0.10587537 0.1053607  0.08928004]\n",
      " [0.10057895 0.092094   0.09016225 0.10703652 0.10511294 0.10183358\n",
      "  0.10055488 0.10764064 0.10808598 0.08690024]\n",
      " [0.09029973 0.0945418  0.08552486 0.12552662 0.10761587 0.10054391\n",
      "  0.08433338 0.08771284 0.11760375 0.10629725]\n",
      " [0.0981931  0.1031613  0.08737293 0.11265976 0.11496416 0.10253236\n",
      "  0.1033365  0.08966706 0.09707976 0.09103308]\n",
      " [0.11304084 0.08742478 0.09220426 0.11990372 0.10311365 0.09794552\n",
      "  0.09216922 0.09725438 0.10251341 0.09443018]\n",
      " [0.11655124 0.09991398 0.0865179  0.09267577 0.10543169 0.09519528\n",
      "  0.10224088 0.10325931 0.10009763 0.0981163 ]\n",
      " [0.11046083 0.10036369 0.0899228  0.10248403 0.10187773 0.08988902\n",
      "  0.10068142 0.10004772 0.10401271 0.10026   ]\n",
      " [0.09877604 0.10041026 0.10401832 0.09437118 0.0955677  0.11049308\n",
      "  0.10603421 0.08886209 0.08966424 0.11180288]\n",
      " [0.10528605 0.0962546  0.09819542 0.10038967 0.10350697 0.10384412\n",
      "  0.10095968 0.09709933 0.10263962 0.09182453]\n",
      " [0.1029703  0.10793393 0.09958714 0.09168101 0.09639129 0.09088311\n",
      "  0.09510655 0.10297228 0.10443862 0.10803577]\n",
      " [0.10520518 0.0974287  0.09595201 0.11361951 0.09643333 0.10905244\n",
      "  0.09045258 0.08630246 0.11153854 0.09401529]\n",
      " [0.11419212 0.09794788 0.10230464 0.10031091 0.09813476 0.09231058\n",
      "  0.09803686 0.10299955 0.09105383 0.10270896]\n",
      " [0.09518473 0.09156185 0.09319811 0.11584448 0.11802755 0.1051515\n",
      "  0.09713063 0.08902662 0.10283392 0.09204063]\n",
      " [0.11315608 0.08489534 0.1059266  0.10333478 0.10716895 0.09384473\n",
      "  0.09430925 0.09901636 0.09705461 0.10129334]\n",
      " [0.10579186 0.09895327 0.09011532 0.10747369 0.11129245 0.0955079\n",
      "  0.09796389 0.09029827 0.09932085 0.10328258]\n",
      " [0.10687058 0.08981176 0.08347904 0.10492678 0.09703153 0.09182345\n",
      "  0.11135753 0.11182809 0.10818341 0.09468781]\n",
      " [0.11485784 0.10549882 0.0881308  0.0945724  0.10776623 0.10002949\n",
      "  0.09054058 0.0960847  0.10917119 0.09334793]\n",
      " [0.12650089 0.10557253 0.09207474 0.10143707 0.09437469 0.08065376\n",
      "  0.11069854 0.10950123 0.09714899 0.08203751]\n",
      " [0.12258355 0.09364615 0.08454219 0.10582717 0.1045648  0.10178262\n",
      "  0.09251782 0.1052383  0.10252574 0.08677157]\n",
      " [0.10893898 0.08947595 0.09427162 0.12071204 0.1090379  0.08656315\n",
      "  0.10099928 0.09296135 0.10622909 0.09081069]\n",
      " [0.10874455 0.09370486 0.0954928  0.0953257  0.10127216 0.09973671\n",
      "  0.10010252 0.09551388 0.10286551 0.10724134]\n",
      " [0.1054648  0.09801639 0.08800809 0.10005278 0.12116811 0.100894\n",
      "  0.09041636 0.10293745 0.09628287 0.0967591 ]\n",
      " [0.10066603 0.11301673 0.10010424 0.08908228 0.09486773 0.0902421\n",
      "  0.10783854 0.10204508 0.09254084 0.10959648]\n",
      " [0.10703933 0.10426414 0.08546387 0.11086387 0.11112892 0.09928398\n",
      "  0.09477592 0.09922082 0.08993281 0.09802633]\n",
      " [0.10197982 0.1067456  0.0914906  0.10417058 0.0992221  0.1068745\n",
      "  0.09959777 0.10885379 0.09108911 0.08997612]\n",
      " [0.11372084 0.10944805 0.09606335 0.09594033 0.10498537 0.10141549\n",
      "  0.09395801 0.08872299 0.0915552  0.1041904 ]]\n",
      "INFO:tensorflow:step = 1, loss = 2.286548\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2942805.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-11-05:20:53\n",
      "INFO:tensorflow:Restoring parameters from /home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/model.ckpt-10\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-11-05:20:54\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.1073, global_step = 10, loss = 2.30187\n",
      "{'global_step': 10, 'accuracy': 0.1073, 'loss': 2.30187}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04e9f6a8d0>, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_model_dir': '/home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/', '_is_chief': True, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_type': 'worker', '_num_ps_replicas': 0, '_task_id': 0, '_keep_checkpoint_max': 5, '_service': None}\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-11-05:21:10\n",
      "INFO:tensorflow:Restoring parameters from /home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/model.ckpt-10\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-11-05:21:10\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.1073, global_step = 10, loss = 2.30187\n",
      "{'global_step': 10, 'accuracy': 0.1073, 'loss': 2.30187}\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/home/hpc/github/deep-learning-models/TensorFlow_Tutorial/ConvNet/model_checkpoint/\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "    \n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
